{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B: Pitched/Percussive Binary classification\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset.aGPTset.ExpressiveGuitarTechniquesDataset as agptset\n",
    "import os\n",
    "import librosa\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "import am24utils\n",
    "from am24utils import Run\n",
    "\n",
    "dataset = agptset.import_db()\n",
    "\n",
    "DOTEST = False\n",
    "VERBOSE = False\n",
    "DB_PATH = 'dataset/aGPTset'\n",
    "printVerbose = lambda x: print(x) if VERBOSE else None\n",
    "MULTIPROCESSING = False\n",
    "\n",
    "if MULTIPROCESSING:\n",
    "    import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Filtering the Dataset...\")\n",
    "filtered_notes_db, filtered_files_db = am24utils.filter_files_db(dataset)\n",
    "#make sure that no audio_file_path contains \"impro\"\n",
    "assert filtered_notes_db.index.get_level_values(1).str.contains('impro').sum() == 0, \"Some audio_file_path contain 'impro' (%i)\"%(filtered_notes_db.index.get_level_values(1).str.contains('impro').sum())\n",
    "print(\"Done (%i notes in the filtered db).\"%len(filtered_notes_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onsetlist_filename_ispercussive(filtered_notes_db:pd.DataFrame, filtered_files_db:pd.DataFrame):\n",
    "    onsetlist = []\n",
    "    filenames = []\n",
    "    players = []\n",
    "    ispercussive = []\n",
    "    for file in filtered_notes_db.index.get_level_values(1).unique():\n",
    "        if file in filtered_files_db.index:\n",
    "            afp = filtered_files_db[filtered_files_db.index == file].full_audiofile_path.values\n",
    "            assert len(afp) == 1, \"More than one audio file path for file %s\"%file\n",
    "            filenames.append(afp[0])\n",
    "            cur_onset_list = filtered_notes_db.loc[filtered_notes_db.index.get_level_values(1) == file].onset_label_samples.values\n",
    "            cur_isPercussive = filtered_notes_db.loc[filtered_notes_db.index.get_level_values(1) == file].isPercussive.values\n",
    "            assert len(cur_onset_list) == len(cur_isPercussive), \"Onset list and isPercussive have different lengths\"\n",
    "            # print('%s has %i onsets and %i isPercussive'%(file,len(cur_onset_list),len(cur_isPercussive)))\n",
    "            cur_onset_list = [int(x) for x in cur_onset_list]\n",
    "            onsetlist.append(cur_onset_list)\n",
    "            cur_isPercussive = [True if 'true' in x.lower() else False for x in cur_isPercussive]\n",
    "            ispercussive.append(cur_isPercussive)\n",
    "            cur_player = filtered_files_db[filtered_files_db.index == file].player_id.values\n",
    "            assert len(cur_player) == 1, \"More than one player for file %s\"%file\n",
    "            cur_player = int(cur_player[0])\n",
    "            players.append(cur_player)\n",
    "        else:\n",
    "            raise ValueError(\"File %s not found in the files db\"%file)\n",
    "        \n",
    "    return onsetlist, filenames, ispercussive, players\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "onsetlist,filenames,ispercussive,playerlist  = get_onsetlist_filename_ispercussive(filtered_notes_db,filtered_files_db)\n",
    "assert len(onsetlist) == len(filenames) == len(ispercussive) == len(playerlist), \"Different lengths for onsetlist, filenames, ispercussive and playerlist\"\n",
    "\n",
    "packedData = (onsetlist,filenames,ispercussive,playerlist)\n",
    "# if DOTEST:\n",
    "#     packedData = (onsetlist[:10],filenames[:10],ispercussive[:10],playerlist[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from importlib import reload\n",
    "#reload(am24utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_compute_features_for_file(cur_filename, \n",
    "                                       cur_onsetlist, \n",
    "                                       cur_isOnsetPercussivelist, \n",
    "                                       cur_player,\n",
    "                                       window_size_samples,\n",
    "                                       onset_perturbation_distribution,\n",
    "                                       onset_perturbation_max_samples, \n",
    "                                       onset_perturbation_min_samples):\n",
    "    # print('Processing file %s'%cur_filename)\n",
    "    assert len(cur_onsetlist) == len(cur_isOnsetPercussivelist), \"onsetlist and isOnsetPercussivelist have different lengths (%i != %i)\"%(len(cur_onsetlist), len(cur_isOnsetPercussivelist))\n",
    "    if onset_perturbation_distribution is not None:\n",
    "        # print('Applying onset perturbation to file %s'%cur_filename)\n",
    "        cur_onsetlist = am24utils.apply_onset_perturbation(cur_onsetlist, onset_perturbation_distribution, onset_perturbation_max_samples, onset_perturbation_min_samples)\n",
    "\n",
    "    # print('Computing features for file %s'%cur_filename)\n",
    "    Xfn, yfn = am24utils.get_Xy(cur_filename, cur_onsetlist, cur_isOnsetPercussivelist, window_size_samples)\n",
    "    \n",
    "    assert len(Xfn) == len(yfn), \"Xfn and yfn have different lengths (%i != %i)\"%(len(Xfn), len(yfn))\n",
    "\n",
    "    print('.',end='', flush=True)\n",
    "    playerlist = [cur_player]*len(Xfn)\n",
    "    return Xfn, yfn,playerlist\n",
    "\n",
    "def run_taskB(runs, packedData, classifier='KNN'):\n",
    "    onsetlist_list,filenames_list,isOnsetPercussive_list, player_list = packedData\n",
    "    assert len(onsetlist_list) == len(filenames_list) == len(isOnsetPercussive_list) == len(player_list), \"Different lengths for onsetlist_list, filenames_list, isOnsetPercussive_list and player_list\"\n",
    "    for ridx,run in enumerate(runs):\n",
    "        # Add color and bold to the print\n",
    "        print('Running task B for Run:%s [%i,%i]'%(run.name,ridx+1,len(runs)), end='\\r')\n",
    "        print('+--%s--Arguments--------------+'%(run.name))\n",
    "        print('| Window size: %i'%run.window_size_samples)\n",
    "        print('| Onset perturbation distribution: %s'%run.onset_perturbation_distribution)\n",
    "        print('| Onset perturbation max samples: %i'%run.onset_perturbation_max_samples)\n",
    "        print('| Onset perturbation min samples: %i'%run.onset_perturbation_min_samples)\n",
    "        print('+-------------------------------------+')\n",
    "\n",
    "\n",
    "        X,y,group = [],[],[]\n",
    "        if MULTIPROCESSING:\n",
    "            # replace previous commented block with parallel processing\n",
    "            pool = mp.Pool(mp.cpu_count()//2)\n",
    "            # results = [pool.apply_async(load_and_compute_features_for_file, args=(os.path.join(DB_PATH,filenames_list[i]), onsetlist_list[i], isOnsetPercussive_list[i], player_list[i])) for i in range(len(onsetlist_list))]\n",
    "            results = [pool.apply_async(load_and_compute_features_for_file, \n",
    "                        args=(os.path.join(DB_PATH,filenames_list[i]), \n",
    "                            onsetlist_list[i], \n",
    "                            isOnsetPercussive_list[i], \n",
    "                            player_list[i], \n",
    "                            run.window_size_samples, \n",
    "                            run.onset_perturbation_distribution, \n",
    "                            run.onset_perturbation_max_samples, \n",
    "                            run.onset_perturbation_min_samples)) for i in range(len(onsetlist_list))]\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            print('All files processed.')\n",
    "            for r in results:\n",
    "                Xfnret, yfnret, playervecret = r.get()\n",
    "                X.extend(Xfnret)\n",
    "                y.extend(yfnret)\n",
    "                group.extend(playervecret)\n",
    "        else:\n",
    "            for i in range(len(onsetlist_list)):\n",
    "                Xfn, yfn, playervec = load_and_compute_features_for_file(os.path.join(DB_PATH,filenames_list[i]),\n",
    "                                                                        onsetlist_list[i], \n",
    "                                                                        isOnsetPercussive_list[i], \n",
    "                                                                        player_list[i], \n",
    "                                                                        run.window_size_samples, \n",
    "                                                                        run.onset_perturbation_distribution, \n",
    "                                                                        run.onset_perturbation_max_samples, \n",
    "                                                                        run.onset_perturbation_min_samples)\n",
    "                X.extend(Xfn)\n",
    "                y.extend(yfn)\n",
    "                group.extend(playervec) # Add the player id to the group list, repeated for each onset\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        assert len(X) == len(y), \"X and y have different lengths (%i != %i)\"%(len(X), len(y))\n",
    "        assert len(X) == len(group), \"X and group have different lengths (%i != %i)\"%(len(X), len(group))\n",
    "        # print('X',X)\n",
    "        # print('y',y)\n",
    "        # print(group)\n",
    "        \n",
    "\n",
    "        from sklearn.model_selection import StratifiedGroupKFold\n",
    "        N_FOLDS = 3\n",
    "        skf = StratifiedGroupKFold(n_splits=N_FOLDS)\n",
    "\n",
    "        skf.get_n_splits(X, y, group)\n",
    "        for fold_idx, (train_index, test_index) in enumerate(skf.split(X, y, group)):\n",
    "            X_train, X_test = np.array(X)[train_index], np.array(X)[test_index]\n",
    "            y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
    "            group_train, group_test = np.array(group)[train_index], np.array(group)[test_index]\n",
    "            print('Fold %i/%i'%(fold_idx+1,N_FOLDS))\n",
    "            print('Train:', len(X_train), len(y_train),'Groups: ', sorted(list(set(group_train))))\n",
    "            print('Test:', len(X_test), len(y_test),'Groups: ', sorted(list(set(group_test))))\n",
    "            \n",
    "            # For each test set, print the percentage of percussive and pitched notes\n",
    "            percussive_perc = sum(y_test)/len(y_test)\n",
    "            pitched_perc = 1 - percussive_perc\n",
    "            print('Test Percussive: %.2f%%'%(percussive_perc*100))\n",
    "            print('Test Pitched: %.2f%%'%(pitched_perc*100))\n",
    "\n",
    "\n",
    "\n",
    "            # Use SMOTE to balance the classes\n",
    "            # Print the percentage of percussive and pitched notes before SMOTE\n",
    "            percussive_perc = sum(y_train)/len(y_train)\n",
    "            pitched_perc = 1 - percussive_perc\n",
    "            print('Train Percussive (before SMOTE): %.2f%%'%(percussive_perc*100))\n",
    "            print('Train Pitched (before SMOTE): %.2f%%'%(pitched_perc*100))\n",
    "            \n",
    "            from imblearn.over_sampling import SMOTE\n",
    "            smote = SMOTE()\n",
    "            print('Balancing classes with SMOTE ...')\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "            \n",
    "            # Print the percentage of percussive and pitched notes after SMOTE\n",
    "            percussive_perc = sum(y_train)/len(y_train)\n",
    "            pitched_perc = 1 - percussive_perc\n",
    "            print('Train Percussive (after SMOTE): %.2f%%'%(percussive_perc*100))\n",
    "            print('Train Pitched (after SMOTE): %.2f%%'%(pitched_perc*100))\n",
    "        \n",
    "            if classifier.upper()=='KNN':\n",
    "                from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "                # Train KNN\n",
    "                print('Training', classifier, '...')\n",
    "                knn = KNN(n_neighbors=3)\n",
    "                knn.fit(X_train, y_train)\n",
    "                \n",
    "                # Test\n",
    "                y_pred = knn.predict(X_test)\n",
    "            elif classifier.upper()=='SVM':\n",
    "                from sklearn.svm import SVC\n",
    "                # Train SVM\n",
    "                svm = SVC()\n",
    "                print('Training', classifier, '...')\n",
    "                svm.fit(X_train, y_train)\n",
    "                \n",
    "                # Test\n",
    "                y_pred = svm.predict(X_test)\n",
    "            \n",
    "            # # Metrics\n",
    "            classification_report = sk.metrics.classification_report(y_test, y_pred, labels=[True, False],target_names=['Percussive', 'Pitched'])\n",
    "            print('-Classification FOLD %i/%i-'%(fold_idx+1,N_FOLDS))\n",
    "            print('\\t\\t\\t'+classification_report.replace('\\n','\\n\\t\\t\\t'))\n",
    "            print('\\n\\n')\n",
    "\n",
    "            confusion_matrix = sk.metrics.confusion_matrix(y_test, y_pred, labels=[True, False], )\n",
    "            print('-Confusion Matrix FOLD %i/%i-'%(fold_idx+1,N_FOLDS))\n",
    "            print('\\t\\t\\t'+str(confusion_matrix).replace('\\n','\\n\\t\\t\\t'))\n",
    "            print('\\n\\n')\n",
    "            print('\\n\\n')\n",
    "            \n",
    "        \n",
    "            run.foldresults.append({\n",
    "                'classification_report': classification_report,\n",
    "                'confusion_matrix': confusion_matrix,\n",
    "                'accuracy': sk.metrics.accuracy_score(y_test, y_pred),\n",
    "                'dictclassifiction_report' : sk.metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "            })\n",
    "        print('Run %s done.'%run.name)\n",
    "\n",
    "        # TODO: CHECK WHY THIS PRINTED \"Average classification report over %i folds: 9\" WHILE WE WERE RUNNING 3 FOLDS ??????????\n",
    "        print('Average classification report over %i folds:', len(run.foldresults))\n",
    "        # print(\"'Average classification report over %i folds:\"%N_FOLDS)\n",
    "        mean_dict = am24utils.report_average([r['dictclassifiction_report'] for r in run.foldresults])\n",
    "        mean_accuracy = sum([r['accuracy'] for r in run.foldresults])/len(run.foldresults)\n",
    "        run.results = {'mean_classification_report_dict': mean_dict,'mean_classification_report_str': am24utils.classification_report_dict2print(mean_dict), 'mean_accuracy': mean_accuracy, 'number_folds': N_FOLDS}\n",
    "        print(run.results['mean_classification_report_str'])\n",
    "        \n",
    "to_run = am24utils.get_run_list()\n",
    "\n",
    "for ridx,run in enumerate(to_run):\n",
    "    print(run.name)\n",
    "\n",
    "           \n",
    "run_taskB(to_run, packedData=packedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "import pickle, datetime\n",
    "\n",
    "resdir_path = os.path.join('results','task-B','date_%s'%(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")))\n",
    "os.makedirs(resdir_path)\n",
    "\n",
    "bakfilename  = 'taskB_KNN_results.pickle'\n",
    "\n",
    "with open(os.path.join(resdir_path,bakfilename), 'wb') as f:\n",
    "    pickle.dump(to_run, f)\n",
    "    \n",
    "\n",
    "am24utils.plot_runs(to_run, arg_metric='mean_f1')\n",
    "plt.savefig(os.path.join(resdir_path,'accuracy_KNN.png'))\n",
    "plt.savefig(os.path.join(resdir_path,'accuracy_KNN.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous_run = to_run[0]\n",
    "# for run in to_run[1:]:\n",
    "#     print('Run %s'%run.name)\n",
    "#     print(\"Len(Fold_Results): \",len(run.foldresults))\n",
    "#     print(\"Type: \",type(run.foldresults))\n",
    "#     print(\"Run and Previous Run Fold Results are equal: \",run.foldresults == previous_run.foldresults)\n",
    "#     previos_run = run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST WITH RESNET AND SQUEEZENET\n",
    "\n",
    "def load_and_compute_features_for_file(cur_filename, \n",
    "                                       cur_onsetlist, \n",
    "                                       cur_isOnsetPercussivelist, \n",
    "                                       cur_player,\n",
    "                                       window_size_samples,\n",
    "                                       onset_perturbation_distribution,\n",
    "                                       onset_perturbation_max_samples, \n",
    "                                       onset_perturbation_min_samples):\n",
    "    # print('Processing file %s'%cur_filename)\n",
    "    assert len(cur_onsetlist) == len(cur_isOnsetPercussivelist), \"onsetlist and cur_dynamicslist have different lengths (%i != %i)\"%(len(cur_onsetlist), len(cur_isOnsetPercussivelist))\n",
    "    if onset_perturbation_distribution is not None:\n",
    "        # print('Applying onset perturbation to file %s'%cur_filename)\n",
    "        cur_onsetlist = am24utils.apply_onset_perturbation(cur_onsetlist, onset_perturbation_distribution, onset_perturbation_max_samples, onset_perturbation_min_samples)\n",
    "\n",
    "    # print('Computing features for file %s'%cur_filename)\n",
    "    Xfn, yfn = am24utils.get_Xy(cur_filename, cur_onsetlist, cur_isOnsetPercussivelist, window_size_samples, features=[\"log-mel\",\"mfcc\"])\n",
    "    \n",
    "    assert len(Xfn) == len(yfn), \"Xfn and yfn have different lengths (%i != %i)\"%(len(Xfn), len(yfn))\n",
    "\n",
    "    print('.',end='',flush=True)\n",
    "    playerlist = [cur_player]*len(Xfn)\n",
    "    return Xfn, yfn,playerlist\n",
    "\n",
    "def run_taskB(runs, packedData, classifier='RESNET'):\n",
    "    onsetlist_list,filenames_list,isOnsetPercussive_list, player_list = packedData\n",
    "    assert len(onsetlist_list) == len(filenames_list) == len(isOnsetPercussive_list) == len(player_list), \"Different lengths for onsetlist_list, filenames_list, dynamics_list and player_list\"\n",
    "    for ridx,run in enumerate(runs):\n",
    "        print('Running task B for Run:%s [%i,%i]'%(run.name,ridx+1,len(runs)), end='\\r')\n",
    "        print('+--%s--Arguments--------------+'%(run.name))\n",
    "        print('| Window size: %i'%run.window_size_samples)\n",
    "        print('| Onset perturbation distribution: %s'%run.onset_perturbation_distribution)\n",
    "        print('| Onset perturbation max samples: %i'%run.onset_perturbation_max_samples)\n",
    "        print('| Onset perturbation min samples: %i'%run.onset_perturbation_min_samples)\n",
    "        print('+-------------------------------------+')\n",
    "\n",
    "        '''\n",
    "        # for i in range(len(onsetlist_list)):\n",
    "        #     Xfn, yfn, playervec = load_and_compute_features_for_file(os.path.join(DB_PATH,filenames_list[i]),\n",
    "        #                                                              onsetlist_list[i], \n",
    "        #                                                              dynamics_list[i], \n",
    "        #                                                              player_list[i])\n",
    "        #     X.extend(Xfn)\n",
    "        #     y.extend(yfn)\n",
    "        #     group.extend(playervec) # Add the player id to the group list, repeated for each onset\n",
    "        '''\n",
    "\n",
    "        X,y,group = [],[],[]\n",
    "        if MULTIPROCESSING:\n",
    "            # replace previous commented block with parallel processing\n",
    "            pool = mp.Pool(mp.cpu_count())\n",
    "            # results = [pool.apply_async(load_and_compute_features_for_file, args=(os.path.join(DB_PATH,filenames_list[i]), onsetlist_list[i], dynamics_list[i], player_list[i])) for i in range(len(onsetlist_list))]\n",
    "            results = [pool.apply_async(load_and_compute_features_for_file, \n",
    "                        args=(os.path.join(DB_PATH,filenames_list[i]), \n",
    "                            onsetlist_list[i], \n",
    "                            isOnsetPercussive_list[i], \n",
    "                            player_list[i], \n",
    "                            run.window_size_samples, \n",
    "                            run.onset_perturbation_distribution, \n",
    "                            run.onset_perturbation_max_samples, \n",
    "                            run.onset_perturbation_min_samples)) for i in range(len(onsetlist_list))]\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "            print('All files processed.')\n",
    "            \n",
    "            X,y,group = [],[],[]\n",
    "            for r in results:\n",
    "                Xfnret, yfnret, playervecret = r.get()\n",
    "                X.extend(Xfnret)\n",
    "                y.extend(yfnret)\n",
    "                group.extend(playervecret)\n",
    "        else:\n",
    "            for i in range(len(onsetlist_list)):\n",
    "                Xfn, yfn, playervec = load_and_compute_features_for_file(os.path.join(DB_PATH,filenames_list[i]),\n",
    "                                                                        onsetlist_list[i], \n",
    "                                                                        isOnsetPercussive_list[i], \n",
    "                                                                        player_list[i],\n",
    "                                                                        run.window_size_samples, \n",
    "                                                                        run.onset_perturbation_distribution, \n",
    "                                                                        run.onset_perturbation_max_samples, \n",
    "                                                                        run.onset_perturbation_min_samples)\n",
    "                X.extend(Xfn)\n",
    "                y.extend(yfn)\n",
    "                group.extend(playervec) # Add the player id to the group list, repeated for each onset\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        assert len(X) == len(y), \"X and y have different lengths (%i != %i)\"%(len(X), len(y))\n",
    "        assert len(X) == len(group), \"X and group have different lengths (%i != %i)\"%(len(X), len(group))\n",
    "        # print('X',X)\n",
    "        # print('y',y)\n",
    "        # print(group)\n",
    "        \n",
    "\n",
    "        from sklearn.model_selection import StratifiedGroupKFold, KFold\n",
    "        N_FOLDS = 3\n",
    "        skf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "        kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "        skf.get_n_splits(X, y, group)\n",
    "        run.results = []\n",
    "        for fold_idx, (train_index, test_index) in enumerate(skf.split(X, y, group)):\n",
    "        # for fold_idx, (train_index, test_index) in enumerate(kf.split(X, y, group)):\n",
    "            X_features = [x[1:] for x in X]\n",
    "            X_specs = [x[0] for x in X]\n",
    "            X_train, X_test = np.array(X_features)[train_index], np.array(X_features)[test_index]\n",
    "            S_train, S_test = np.array(X_specs)[train_index], np.array(X_specs)[test_index]\n",
    "            y_train, y_test = np.array(y)[train_index], np.array(y)[test_index]\n",
    "            group_train, group_test = np.array(group)[train_index], np.array(group)[test_index]\n",
    "            print('Fold %i/%i'%(fold_idx+1,N_FOLDS))\n",
    "            print('Train:', len(X_train), len(y_train),'Groups: ', sorted(list(set(group_train))))\n",
    "            print('Test:', len(X_test), len(y_test),'Groups: ', sorted(list(set(group_test))))\n",
    "            \n",
    "            \n",
    "            # Use SMOTE to balance the classes\n",
    "            # Print the percentage of percussive and pitched notes before SMOTE\n",
    "            percussive_perc = sum(y_train)/len(y_train)\n",
    "            pitched_perc = 1 - percussive_perc\n",
    "            print('Train Percussive (before SMOTE): %.2f%%'%(percussive_perc*100))\n",
    "            print('Train Pitched (before SMOTE): %.2f%%'%(pitched_perc*100))\n",
    "          \n",
    "            # Use SMOTE to balance the classes\n",
    "            from imblearn.over_sampling import SMOTE\n",
    "            smote = SMOTE()\n",
    "            print('Balancing classes with SMOTE ...')\n",
    "            shape_train = S_train.shape[1:]\n",
    "            X_resampled, y_train = smote.fit_resample(S_train.reshape(-1, shape_train[0]*shape_train[1]*shape_train[2]), y_train)\n",
    "            # Reshape the data\n",
    "            S_train = X_resampled.reshape(-1, shape_train[0], shape_train[1], shape_train[2])\n",
    "            \n",
    "            # Print the percentage of percussive and pitched notes after SMOTE\n",
    "            percussive_perc = sum(y_train)/len(y_train)\n",
    "            pitched_perc = 1 - percussive_perc\n",
    "            print('Train Percussive (after SMOTE): %.2f%%'%(percussive_perc*100))\n",
    "            print('Train Pitched (after SMOTE): %.2f%%'%(pitched_perc*100))\n",
    "\n",
    "\n",
    "            if classifier.upper()=='KNN':\n",
    "                from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "                # Train KNN\n",
    "                print('Training', classifier, '...')\n",
    "                knn = KNN(n_neighbors=3)\n",
    "                knn.fit(X_train, y_train)\n",
    "                \n",
    "                # Test\n",
    "                y_pred = knn.predict(X_test)\n",
    "            elif classifier.upper()=='SVM':\n",
    "                from sklearn.svm import SVC\n",
    "                # Train SVM\n",
    "                svm = SVC()\n",
    "                print('Training', classifier, '...')\n",
    "                svm.fit(X_train, y_train)\n",
    "                \n",
    "                # Test\n",
    "                y_pred = svm.predict(X_test)\n",
    "                \n",
    "            # TODO: uncomment NN classifier and test it    \n",
    "            elif classifier.upper()=='RESNET':\n",
    "                import torch\n",
    "                from am24utils import AudioResNet\n",
    "                # Train ResNet for audio classification\n",
    "                device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "                resnet = AudioResNet(num_classes=2, fine_tuning=True).to(device)\n",
    "                #am24utils.save_or_reset_weights(resnet, 'resnet_weights_starting_weights.pth')\n",
    "                print('Training', classifier, '...')\n",
    "                resnet.fit(S_train, y_train)\n",
    "                \n",
    "                # Save the weights\n",
    "                #am24utils.save_or_reset_weights(resnet, f'squeezenet_weights_f{fold_idx+1}/{N_FOLDS}.pth')\n",
    "                \n",
    "                # Test\n",
    "                _, y_pred = resnet.test(S_test, y_test)\n",
    "                \n",
    "                resnet.cpu()\n",
    "                resnet = None\n",
    "                \n",
    "                del resnet\n",
    "                # Free memory\n",
    "                torch.cuda.empty_cache()\n",
    "                # Use garbage collector\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                \n",
    "            elif classifier.upper()=='SQUEEZENET':\n",
    "                import torch\n",
    "                from am24utils import AudioSqueezeNet\n",
    "                # Train ResNet for audio classification\n",
    "                device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "                squeezenet = AudioSqueezeNet(num_classes=2).to(device)\n",
    "                #am24utils.save_or_reset_weights(squeezenet, 'squeezenet_starting_weights.pth')\n",
    "                print('Training', classifier, '...')\n",
    "                squeezenet.fit(S_train, y_train)\n",
    "                \n",
    "                # Save the weights\n",
    "                #am24utils.save_or_reset_weights(squeezenet, f'squeezenet_weights_f{fold_idx+1}/{N_FOLDS}.pth')\n",
    "                \n",
    "                # Test\n",
    "                _, y_pred = squeezenet.test(S_test, y_test)\n",
    "                \n",
    "                squeezenet.cpu()\n",
    "                squeezenet = None\n",
    "                \n",
    "                del squeezenet\n",
    "                # Free memory\n",
    "                torch.cuda.empty_cache()\n",
    "                # Use garbage collector\n",
    "                import gc\n",
    "                gc.collect()\n",
    "                \n",
    "            \n",
    "            # # Metrics\n",
    "            classification_report = sk.metrics.classification_report(y_test, y_pred, labels=[True, False],target_names=['Percussive', 'Pitched'])\n",
    "            print('-Classification FOLD %i/%i-'%(fold_idx+1,N_FOLDS))\n",
    "            print('\\t\\t\\t'+classification_report.replace('\\n','\\n\\t\\t\\t'))\n",
    "            print('\\n\\n')\n",
    "\n",
    "            confusion_matrix = sk.metrics.confusion_matrix(y_test, y_pred, labels=[True, False], )\n",
    "            print('-Confusion Matrix FOLD %i/%i-'%(fold_idx+1,N_FOLDS))\n",
    "            print('\\t\\t\\t'+str(confusion_matrix).replace('\\n','\\n\\t\\t\\t'))\n",
    "            print('\\n\\n')\n",
    "            print('\\n\\n')\n",
    "            \n",
    "        \n",
    "            run.foldresults.append({\n",
    "                'classification_report': classification_report,\n",
    "                'confusion_matrix': confusion_matrix,\n",
    "                'accuracy': sk.metrics.accuracy_score(y_test, y_pred),\n",
    "                'dictclassifiction_report' : sk.metrics.classification_report(y_test, y_pred, output_dict=True)\n",
    "            })\n",
    "        print('Run %s done.'%run.name)\n",
    "\n",
    "        print('Average classification report over %i folds:',len(run.foldresults))\n",
    "        mean_dict = am24utils.report_average([r['dictclassifiction_report'] for r in run.foldresults])\n",
    "        mean_accuracy = sum([r['accuracy'] for r in run.foldresults])/len(run.foldresults)\n",
    "        run.results = {'mean_classification_report_dict': mean_dict,'mean_classification_report_str': am24utils.classification_report_dict2print(mean_dict), 'mean_accuracy': mean_accuracy, 'number_folds': N_FOLDS}\n",
    "        print(run.results['mean_classification_report_str'])\n",
    "\n",
    "\n",
    "# TEST_WINDOWSIZES_VALUES = [4800]\n",
    "# TEST_PERTURBATION_DISTRIBUTIONS = ['normal']\n",
    "# TEST_PERTURBATION_MAXSAMPLES = [0]\n",
    "\n",
    "# to_run = am24utils.get_run_list(winsizes = TEST_WINDOWSIZES_VALUES,\n",
    "#                  pert_distributions = TEST_PERTURBATION_DISTRIBUTIONS,\n",
    "#                  pert_maxsamples  = TEST_PERTURBATION_MAXSAMPLES)       \n",
    "       \n",
    "       \n",
    "# Create the runs        \n",
    "to_run_NN = am24utils.get_run_list()\n",
    "\n",
    "for ridx,run in enumerate(to_run_NN):\n",
    "    print(run.name)\n",
    "\n",
    "\n",
    "run_taskB(to_run_NN, packedData=packedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, datetime\n",
    "\n",
    "# resdir_path = os.path.join('results','task-B','date_%s'%(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")))\n",
    "# os.makedirs(resdir_path)\n",
    "\n",
    "# resdir_path = os.path.join('results','task-B','date_2024-05-07_13-07-18')\n",
    "\n",
    "bakfilename  = 'taskB_ResNet_results.pickle'\n",
    "\n",
    "with open(os.path.join(resdir_path,bakfilename), 'wb') as f:\n",
    "    pickle.dump(to_run_NN, f)\n",
    "    \n",
    "\n",
    "am24utils.plot_runs(to_run_NN, arg_metric='mean_f1')\n",
    "plt.savefig(os.path.join(resdir_path,'accuracy_ResNet.png'))\n",
    "plt.savefig(os.path.join(resdir_path,'accuracy_ResNet.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle, datetime\n",
    "\n",
    "# resdir_path = os.path.join('results','task-B','date_%s'%(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")))\n",
    "# os.makedirs(resdir_path)\n",
    "\n",
    "# bakfilename  = 'taskB_results.pickle'\n",
    "\n",
    "# with open(os.path.join(resdir_path,bakfilename), 'wb') as f:\n",
    "#     pickle.dump(to_run, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies_toplot = [run.results['mean_accuracy'] for run in to_run]\n",
    "# runnames_labels = [run.name for run in to_run]\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(1.5*len(accuracies_toplot),5))\n",
    "# plt.bar(runnames_labels, accuracies_toplot)\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.title('Accuracy')\n",
    "# # plt.show()\n",
    "\n",
    "# dirname = os.path.join('results','task-B','date_%s'%(datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")))\n",
    "# os.makedirs(dirname)\n",
    "\n",
    "# am24utils.plot_runs(to_run_NN)\n",
    "# plt.savefig(os.path.join(resdir_path,'accuracy.png'))\n",
    "# plt.savefig(os.path.join(resdir_path,'accuracy.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
